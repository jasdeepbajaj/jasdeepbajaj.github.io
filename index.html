<!DOCTYPE html>
<html lang="en">

  <head>
    <title> Jasdeep Bajaj</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <!--<title>Agency - Start Bootstrap Theme</title>-->

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Kaushan+Script' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700' rel='stylesheet' type='text/css'>

    <!-- Custom styles for this template -->
    <link href="css/agency.min.css" rel="stylesheet">

  </head>

  <body id="page-top">

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark fixed-top" id="mainNav">
      <div class="container">
        <a class="navbar-brand js-scroll-trigger" href="#page-top">Jasdeep Bajaj</a>
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          Menu
          <i class="fas fa-bars"></i>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav text-uppercase ml-auto">
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#portfolio">Projects</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#TechnicalSkills">Skills</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#team">Contact Me</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <!-- Header -->
    <header class="masthead">
      <div class="container">
        <div class="intro-text">           
          <div class="intro-heading text-uppercase"style="background-color: rgba(26, 26, 26, 0.7); color:rgba(253, 201, 43, 1); border-radius:5px;">Jasdeep Bajaj</div>
          <div class="intro-lead-in">Future Roboticist in the Making</div>
          <a class="btn btn-primary btn-xl text-uppercase js-scroll-trigger" href="https://drive.google.com/file/d/1sERH-4aW_wevQsT2XIVe7wwq9EvfJS8E/view?usp=sharing">Resume</a>
        </div>
      </div>
    </header>

    <!-- Portfolio Grid -->
    <section class="bg-light" id="portfolio">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading text-uppercase">Projects</h2>
            <h3 class="section-subheading text-muted">August 2022 ~ Now</h3>
          </div>
        </div>
        <div class="row">

          <!-- Project1 -->
         <div class="col-md-4 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#MAPF">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                  <i class="fas fa-plus fa-3x"></i>
                </div>
              </div>
              <img class="img-fluid" src="img/portfolio/MAPF/result5.gif" alt="" width="300" height="200">
            </a>
            <div class="portfolio-caption">
              <h4>Multi Agent Path Finding</h4>
              <p class="text-muted">Conflict Based Search | Space-Time A* <br>Smart Navigation: Agents Conquering Gridworlds with CBS and Space-Time A*</p>
            </div>
          </div>

          <!-- Project2 -->
          <div class="col-md-4 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#healerbaxter">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                  <i class="fas fa-plus fa-3x"></i>
                </div>
              </div>
              <img class="img-fluid" src="img/portfolio/healer_baxter/healer.gif" alt="" width="400" height="300">
            </a>
            <div class="portfolio-caption">
              <h4>Healer Baxter</h4>
              <p class="text-muted">Deep Learning | CV | Motion Planning<br>Baxter Robot play the piano based on detected human emotion</p>
            </div>
          </div>

          <!-- Project3 -->
          <div class="col-md-4 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#terminator">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                  <i class="fas fa-plus fa-3x"></i>
                </div>
              </div>
              <img class="img-fluid" src="img/portfolio/mind_proj/nerfgun.gif" alt="" width="400" height="300">
            </a>
            <div class="portfolio-caption">
              <h4>Terminator</h4>
              <p class="text-muted">ROS | CV | Motion Planning<br>Baxter Robot pick up a nerf gun, locate a cup, pull the nerf gun trigger to shoot the cup when given a user input, and move to a final pose</p>
            </div>
        </div>

            <!-- Project4 -->
            <div class="col-md-4 col-sm-6 portfolio-item">
                <a class="portfolio-link" data-toggle="modal" href="#kuka">
                  <div class="portfolio-hover">
                    <div class="portfolio-hover-content">
                      <i class="fas fa-plus fa-3x"></i>
                    </div>
                  </div>
                  <img class="img-fluid" src="img/portfolio/manipulation_proj/manipulation.gif" alt="" width="400" height="300">
                </a>
                <div class="portfolio-caption">
                  <h4>Mobile Manipulation</h4>
                  <p class="text-muted">Manipulation | Motion Planning<br>KUKA youBot to pick up a block at the start location and carry it to the desired location in the simulation software V-REP</p>
                </div>
              </div>

          <!-- Project5 -->
          <div class="col-md-4 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#pushinggrasping">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                  <i class="fas fa-plus fa-3x"></i>
                </div>
              </div>
              <img class="img-fluid" src="img/portfolio/pushing_grasping/rep.gif" alt="" width="400" height="300">
            </a>
            <div class="portfolio-caption">
              <h4>Visual Pushing and Grasping</h4>
              <p class="text-muted">Deep Reinforcement Learning | Docker <br>Train robotic agents to learn to plan pushing and grasping actions for manipulation with deep reinforcement learning</p>
            </div>
          </div>

          <!-- Project6 -->
          <div class="col-md-4 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#panorama">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                  <i class="fas fa-plus fa-3x"></i>
                </div>
              </div>
              <img class="img-fluid" src="img/portfolio/image_mosaic/panorama.gif" alt="" width="400" height="300">
            </a>
            <div class="portfolio-caption">
              <h4>ImageMosaic</h4>
              <p class="text-muted">Computer Vision<br>Create an image panorama by stitching a set
                of images together</p>
            </div>
          </div>

          <!-- Project7 -->
          <div class="col-md-4 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#dynamics">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                  <i class="fas fa-plus fa-3x"></i>
                </div>
              </div>
              <img class="img-fluid" src="img/portfolio/dynamics_proj/314project.gif" alt="" width="400" height="150">
            </a>
            <div class="portfolio-caption">
              <h4>Pin-triangle Dynamics Simulation </h4>
              <p class="text-muted">Dynamics | Simulation<br>Simulation of a triangle bouncing in the enclosed rectangle</p>
            </div>
          </div>
          
        </div>
      </div>
    </section>

    <!-- Technical Skills -->
    <section  id="TechnicalSkills">
        <div class="container">
          <div class="row">
            <div class="col-lg-12 text-center">
              <h2 class="section-heading text-uppercase">Skills</h2>
              <p></p>
            </div>
          </div>
          <div class="row text-center">
            <div class="col-md-4">
                <span class="fa-stack fa-4x">
                  <img class="mx-auto rounded-circle" src="img/skills/microcontroller.jpeg" alt="" width="120" height="120">  
                </span>
                <h4 class="service-heading">Robotics</h4>
                <p class="text-muted"> ROS,Linux,Git,Gazebo <br> Computer Vision, Machine Learning<br> Motion Planning,Feedback Control,Cloud Computing</p>
            </div>
            <div class="col-md-4">
                <span class="fa-stack fa-4x">
                  <img class="mx-auto rounded-circle" src="img/skills/coding.jpeg" alt="" width="120" height="120">  
                </span>
                <h4 class="service-heading">Programming</h4>
                <p class="text-muted">C++, C，Python, Java, MATLAB, PLC, VHDL</p>
            </div>
            <div class="col-md-4">
              <span class="fa-stack fa-4x">
                <!-- <i class="fas fa-circle fa-stack-2x text-primary"></i> -->
                <img class="mx-auto rounded-circle" src="img/skills/electronicdesign.png" alt="" width="120" height="120">
              </span>
              <h4 class="service-heading">Electrical Engineering</h4>
              <p class="text-muted">Power System, Microprocessor<br>PCB Design, Electronic System Design</p>
            </div>
            <div class="col-md-4">
              <span class="fa-stack fa-4x">
                <img class="mx-auto rounded-circle" src="img/skills/manufacturing.jpeg" alt="" width="120" height="120">  
              </span>
              <h4 class="service-heading">Manufacturing</h4>
              <p class="text-muted"> Laser Cutter, 3D print, soldering </p>
            </div>
            <div class="col-md-4">
              <span class="fa-stack fa-4x">
                <img class="mx-auto rounded-circle" src="img/skills/cad.png" alt="" width="120" height="120">  
              </span>
              <h4 class="service-heading">Mechanical Engineering</h4>
              <p class="text-muted">Onshape, AutoCAD<br> Mechatronics/ Microcontroller</p>
            </div>
            <div class="col-md-4">
              <span class="fa-stack fa-4x">
                <img class="mx-auto rounded-circle" src="img/skills/machine_learning.jpeg" alt="" width="120" height="120">  
              </span>
              <h4 class="service-heading">Research Interest</h4>
              <p class="text-muted">Assistive Robotics, Rehabilation<br>Human Movement Science</p>
            </div>
          </div>
        </div>
      </section>
    
    <!-- contact -->
    <section class="bg-light" id="team">
      <div class="container">
        <div class="row">
            <div class="col-lg-12 max-auto mb-5">
                <img class="mx-auto d-block rounded-circle" src="img/profilepic.jpeg" alt="Avatar" width="300" height="300">
            </div>
          <div class="col-lg-12 text-center">
            <h2 class="section-heading text-uppercase">Contact me</h2>
           
          </div>
        </div>
        <div class="row">
          <div class="col-lg-12">
         

            <div class="team-member">
              
              <h4>Jasdeep Bajaj</h4>
              <p class="text-muted">Master of Science in Mechanical Engineering @ Texas A&M University</p>
              <ul class="list-inline social-buttons">
                <li class="list-inline-item">
                  <a href="https://github.com/jasdeepbajaj">
                    <i class="fab fa-github"></i>
                  </a>
                </li>
                <li class="list-inline-item">
                  <a href="mailto:jasdeepbajaj3@tamu.edu">
                    <i class="fa fa-envelope"></i>
                  </a>
                </li>
                <li class="list-inline-item">
                  <a href="https://www.linkedin.com/in/jasdeepbajaj/">
                    <i class="fab fa-linkedin-in"></i>
                  </a>
                </li>
              </ul>
            </div>
          </div>
          </div>
        </div>
        <div class="row">
          <div class="col-lg-8 mx-auto text-center">
           
          </div>
        </div>
      </div>
    </section>


    <!-- Portfolio Modals -->

    <!-- MAPF -->
    <div class="portfolio-modal modal fade" id="MAPF" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
          <div class="modal-content">
              <div class="close-modal" data-dismiss="modal">
                  <div class="lr">
                      <div class="rl"></div>
                  </div>
              </div>
              <div class="container">
                  <div class="row">
                      <div class="col-lg-8 mx-auto">
                          <div class="modal-body">
                              <!-- Project Details Go Here -->
                              <h3 class="text-uppercase">Multi-Agent Path Finding</h3>
                              <a class="boxed">Path Planning</a>&ensp;<a class="boxed">Motion Planning</a>&ensp;<a class="boxed">Python</a>&ensp;<a class="boxed">Gridworld Navigation</a>&ensp;<a class="boxed">Algorithm Design and Optimization</a>&ensp;
                              <p></p><br>
                              <h4>Brief Description</h4>
                              <p></p>
                              <p>This report presents the development and implementation of a sophisticated multi-agent pathfinding (MAPF) system, designed to 
                                navigate multiple agents—specifically kings on a chessboard—through a complex environment without collisions. The project leverages 
                                advanced algorithmic techniques within a constrained computational framework to address the challenge of sequential agent movements 
                                on a grid with restricted areas. Utilizing a modified A* search algorithm, extended to include temporal and spatial dimensions 
                                (space-time A*), and integrating Conflict-Based Search (CBS) for conflict resolution, this system ensures optimal and collision-free navigation.</p>
                              <p>The system handles the intricacies of MAPF by enforcing strict movement rules that prevent agents from moving into restricted cells
                                 and from ending movements adjacent to each other. The core of the solution involves dynamic constraint generation and management, 
                                 facilitating the detection and resolution of both vertex and edge type collisions.</p>
                              <p>Extensive testing on various scenarios confirms the robustness and efficiency of the planner. The algorithm successfully computes viable
                                 paths for all agents or accurately detects scenarios where no path exists. This project not only showcases a technical solution to a complex 
                                 problem but also contributes to the broader field of robotics and automated systems by providing a scalable model for multi-agent navigation 
                                 in constrained environments.</p>

                              <h4>Algorithm Design and Approach</h4>
                              <p>The core of my solution utilizes a space-time A* search algorithm, modified to incorporate constraints that prevent collisions both in terms
                                 of position and time.</p>
                              <p>• Space-Time A* Algorithm: This involved modifying the traditional A* algorithm to consider time as a dimension, allowing the planner to handle 
                                dynamic constraints across different timesteps.</p>
                              <p>• Conflict-Based Search (CBS): I further enhanced the solution by integrating CBS, an approach that is optimal and complete for solving 
                                multi-agent pathfinding problems. CBS works by detecting conflicts among paths and resolving them by imposing constraints that split the 
                                search space. The algorithm mainly identifies two types of collisions:</p>

                              <p>o “Vertex Type”: A vertex type collision occurs when two or more agents occupy the same cell at the same timestep. For example, consider 
                                a scenario where:</p>
                              <p>▪ King A is supposed to move to cell (x, y) at timestep t.</p>
                              <p>▪ Simultaneously, Agent B also moves to cell (x, y) at timestep t.</p>
                              <p>This results in a vertex collision at cell (x, y) at timestep t, which must be resolved to ensure that the agents can proceed without 
                                interference.</p>

                              <p>o “Edge type”: Edge type collisions, also known as swap collisions, occur when two agents attempt to traverse the edge between two cells 
                                in opposite directions simultaneously. In essence, they "pass" each other in the grid, resulting in a collision. For instance:</p>
                              <p>▪ Agent A moves from cell (x, y) to cell (x+1, y) at timestep t.</p>
                              <p>▪ At the same time, Agent B moves from cell (x+1, y) to cell (x, y) at timestep t.</p>
                              <p>This results in an edge collision between the paths of Agent A and Agent B between timesteps t−1 and t, and it must be resolved to avoid a 
                                conflict in the paths.</p>

                              <h4>Managing Collisions</h4>
                              <p>To manage these collisions, strategies like CBS use a two-level search. The high level of the search builds a constraint tree where each node 
                                represents a set of constraints derived from detected collisions. When a collision is detected, it is resolved by creating constraints that 
                                prevent at least one of the conflicting moves, thereby branching into new nodes in the search tree.</p>
                              <p>For vertex collisions, the constraint might involve preventing one or more agents from entering the conflicting cell at the specific timestep. 
                                For edge collisions, the constraint might prevent one or both of the agents from making their respective moves at the specified timestep.</p>
                              <p>Both types of collisions and their resolutions are central to ensuring that the path-finding algorithm can find viable paths for all agents without 
                                interference, thus guaranteeing that the solution is not only feasible but also optimal in terms of path length and time.</p>
                              
                              <h4>Results and Conclusions</h4>
                              <p>The developed planner successfully met the requirements outlined in the problem statement. It was able to compute paths for the kings or detect the 
                                absence of viable paths (if present) within the stipulated time frame.</p>
                              <img class="img-fluid" src="img/portfolio/MAPF/result5.gif" alt="Result GIF" width="400" height="300">
                              <p>Figure 1: Visualization of the multi-agent pathfinding results</p>
                              <p>This project not only highlighted my technical skills in algorithm design and optimization but also reinforced my ability to apply theoretical concepts 
                                to practical, real-world problems.</p>
                              <ul class="list-inline">
                                  <p class="item-intro text-muted"> <a class="boxed" href="https://github.com/jasdeepbajaj/Multi-Agent-Path-Finding"><font color="red"><b>Github Page</b></font></a></p>
                                  <li>Date: April 2024</li>
                              </ul>
                              <button class="btn btn-primary" data-dismiss="modal" type="button">
                                  <i class="fas fa-times"></i>
                                  Close Project</button>
                          </div>
                      </div>
                  </div>
              </div>
          </div>
      </div>
    </div>


    <!-- Healer Baxter -->
    <div class="portfolio-modal modal fade" id="healerbaxter" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-dialog">
          <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
              <div class="lr">
                <div class="rl"></div>
              </div>
            </div>
            <div class="container">
              <div class="row">
                <div class="col-lg-8 mx-auto">
                  <div class="modal-body">
                    <!-- Project Details Go Here -->
                    <h3 class="text-uppercase">Healer Baxter</h3>
                    <a class="boxed">Deep Learning</a>&ensp;<a class="boxed">Tensorflow</a>&ensp;<a class="boxed">Python</a>&ensp;<a class="boxed">Computer Vision</a>&ensp;<a class="boxed">Motion Planning</a>
                    <p></p>
                    <h4>Brief Description</h4>       
                  	<p>This project aims to use deep learning and manipulation platform to train a two-armed robot to play the piano based on the human emotion.</p>
                  	<p></p>
                    <h4>Motivation</h4>       
                  	<p>We live in an era in which communication seems simpler than any times, a friend is only one text away or one video chat away. Although communication may be easier and faster, people still feel lonely and depression rates have largely increased. Inspired by this circumstance, this project is to design a system that would enable the Baxter Robot to detect the negative emotion of its master and play songs on the piano using both hands to help him/her get rid of the bad feelings.</p>
                    <p></p>
                    <h4>Emotion Detection</h4>
                    <h5>1. Data Description</h5> 
                    <p>The data consists of 48x48 pixel grayscale images of faces. The faces have been automatically registered so that the face is more or less centered and occupies about the same amount of space in each image. The datasets are composed of 28,709 training examples
                        and 3,589 testing examples. The training samples are then divided into two sets namely; Training Set and Validation Set. Training set samples composed of 80% of the original dataset samples and 20% of the samples are specified for validation. </p>
                    <img class="img-fluid d-block mx-auto" src="img/portfolio/healer_baxter/data.png" alt="">
                    <p></p>
                    <h5>2. Data Augmentationg</h5> 
                    <p>In order to avoid overfitting and improve
                      recognition accuracy, the following transforms are perfomed on each image:
                      a. Rescale (1. / 255)
                      B. Rotation (30)
                      b. Shear (0.3)
                      c. Zoom (0.3)
                      d. shift(width:0.4,height:0.4)
                      e. Flip (horizontal)</p>
                    <p></p>
                    <h5>3. Proposed CNN Model</h5>       
                  	<p>The CNN Model I built takes a 48*48 pixels grayscale image as input. This model is composed of 5 convolutional layers, each followed with a max pooling layer, and 2 fully connected layers. I
                        classified images through softmax activation function at the last layer (output layer). The
                      output layer consists of 5 neurons corresponding to 5
                      emotional labels: Angry, Happy, Neutral, Sad and Surprise. </p>
                    <p></p>
                    <img class="img-fluid d-block mx-auto" src="img/portfolio/healer_baxter/CNN_ARC.png" alt="">
                    <p></p>
                  	<h5>Emotion Detection Demo</h5> 
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/s_xAZkpSfBo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                    <h4>Piano Playing</h4>
                    <p>The detected emotion would be written in a text file using basic pyhton I/O function. The piano playing node keep reading this text file and when the emotion "sad" is detected and written in the file, baxter would start playing the piano</p>
                    <h5>Locate keys using AprilTags</h5> 
                    <p>Use pose infomation of the two apriltags in left_arm frame to compute the poses of keys in the baxter base frame</p>
                    <img class="img-fluid d-block mx-auto" src="img/portfolio/healer_baxter/piano.png" alt="">
                    <h5>Piano Playing Demo</h5> 
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/lJ78-UlrxD4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                    <ul class="list-inline">
                    <p><a class="boxed" href="https://github.com/mushenghe/HealerBaxter"><font color="red"><b>Github Page</b> </font></a></p>
                    </ul>
                    <button class="btn btn-primary" data-dismiss="modal" type="button">
                      <i class="fas fa-times"></i>
                      Close Project</button>
                      
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
  
    <!-- Terminator -->
    <div class="portfolio-modal modal fade" id="terminator" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-8 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h3 class="text-uppercase">Terminator</h3>
                  <a class="boxed">ROS</a>&ensp;<a class="boxed">Baxter</a>&ensp;<a class="boxed">Python</a>&ensp;<a class="boxed">Computer Vision</a>&ensp;<a class="boxed">Motion Planning</a>
                  <p></p>         
                  <h4>Brief Description</h4>       
                  <p>The goal of this project is to enable Baxter Robot pick up a nerf gun, locate a cup, pull the nerf gun trigger to shoot the cup when given a user input, and move to a final pose. </p>
                  <h4>Action Sequence</h4> 
                  <p></p>
                  <p>1. Baxter goes through initial calibration and start up sequence. Arms are moved to an initial pose. <br>
                  2. Baxter finds the nerf gun using an AprilTag and its left arm camera<br>
                  3. Baxter moves its left arm to line up with the nerf gun and closes its gripper to pick up the gun<br>
                  4. Once Baxter has the gun, it uses its left arm camera to find a cup using darknet<br>
                  5. Baxter keeps moving its left arm until the cup is in the center of the image produced by the camera<br>
                  6. Baxter moves its right arm to put its grippers around the nerf gun trigger<br>
                  7. Baxter waits for a user input to confirm the firing of the gun<br>
                  8. Baxter keeps waiting until the user tells it to fire<br>
                  9. Baxter pulls the trigger using its right gripper<br>
                  10. Baxter moves to a final pose right after shooting<br></p>
                  <p></p>
                  <h4>Demo</h4>
                  <iframe width="560" height="315" src="https://www.youtube.com/embed/2MRsNefNWmw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                  <p></p>

                  <ul class="list-inline">
                  <p><a class="boxed" href="https://github.com/mushenghe/final-project-terminator"><font color="red"><b>Github Page</font></a></p> </ul>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fas fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>


    <!-- KUKA Manipulation -->
    <div class="portfolio-modal modal fade" id="kuka" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-8 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h3 class="text-uppercase">Mobile Manipulation</h3>
                  <a class="boxed">Manipulation</a>&ensp;<a class="boxed">Motion Planning</a>&ensp;<a class="boxed">VREP</a>
                  <p></p>
                  <h4>Brief Description</h4>
                  <p>The goal of this project is to drive the KUKA youBot to pick up a block at the start location, carry it to the desired location, and put it down in the simulation software V-REP. The project covers the following topics: <br>1. Plan a trajectory for the end-effector of the youBot mobile manipulator. <br>2. Generate the kinematics model of the youBot, consisting of the mobile base with 4 mecanum wheels and the robot arm with 5 joints<br>3. Apply feedback control to drive the robot to implement the desired task<br>4. Conduct the simulations in V-REP</p>                           
                  <h5>First Task Demo</h5>
                  <iframe width="560" height="315" src="https://www.youtube.com/embed/C3QQO7TZn4g" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                  <h5>Second Task Demo</h5>
                  <iframe width="560" height="315" src="https://www.youtube.com/embed/1WKscbUi3HA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                  <p><a class="boxed" href="https://github.com/mushenghe/Mobile-Manipulation-"><font color="red"><b>Github Page</font></a></p>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fas fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Visual Pushing and Grasping -->
    <div class="portfolio-modal modal fade" id="pushinggrasping" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                <div class="rl"></div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                <div class="col-lg-8 mx-auto">
                    <div class="modal-body">
                    <!-- Project Details Go Here -->
                    <h3 class="text-uppercase">Visual Pushing and Grasping</h3>
                    <a class="boxed">Deep Reinforcement Learning</a>&ensp;<a class="boxed">Docker</a>&ensp;<a class="boxed">Pytorch</a>
                    <p></p>
                    <h4>Brief Description</h4> 
                    <p>Most grasping algorithms today often fail to handle scenarios where objects are tightly packed together. They can attempt bad grasps repeatedly to no avail since they can only find accessible grasps. This project proposed to discover and learn synergies between pushing and grasping from experience through model-free deep reinforcement learning.</p>
                    <h5>System Overview</h5> 
                    <p></p>
                    <p></p>
                    <img class="img-fluid d-block mx-auto" src="img/portfolio/pushing_grasping/method.jpg" alt="">
                    <p></p>
                    <h5>Model Input & Output</h5>
                    <p></p>
                    <p>The Q-function is modeled as two feed-forward fully convolutional networks(FCNs) Φp and Φg. FCN Φp is for pushing motion primitive behavior and FCN Φg is for grasping.</p>
                    <p></p>
                    <p>For each individual FCN Φψ:</p>
                    <p></p>
                    <p>Input: the heightmap image representation of the current state</p>
                    <p>Output: a dense pixel-wisemap of Q values with the same image size and resolution as that of the state</p>
                    <p></p>
                    <p>Note: each individual Q value prediction at a pixel p represents the future expected reward of executing primitive ψ at 3D location q where q→p ∈st.</p>  
                    
                    <p></p>
                    <h5>Use the pretrained model</h5> 
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/i_fHtQ-zDkM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                    <ul class="list-inline">
                    <p><a class="boxed" href="https://github.com/mushenghe/visual-pushing-grasping"><font color="red"><b>Github Page</font></a></p> 
                    </ul>
                    <button class="btn btn-primary" data-dismiss="modal" type="button">
                        <i class="fas fa-times"></i>
                        Close Project</button>
                    </div>
                </div>
                </div>
            </div>
            </div>
        </div>
        </div>
      

    <!-- Panorama -->
    <div class="portfolio-modal modal fade" id="panorama" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-8 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h3 class="text-uppercase">ImageMosaic</h3>
                  <a class="boxed">Computer Vision</a>&ensp;<a class="boxed">MATLAB</a>&ensp;<a class="boxed">Python</a>
                  <p></p>
                  <h4>Brief Description</h4>
                  <p>The goal of this project is to Create an image panorama by stitching a set of images together</p>                           
                  <h5>Image Registration</h5>
                  <p>I used SURF to do the feature point extraction and matching, then used random sample consensus(RANSAC) for transform matrix estimation</p>
                  <img class="img-fluid d-block mx-auto" src="img/portfolio/image_mosaic/SURFMatches.jpg" alt="">
                  <h5>Image Warping</h5>
                  <p>Use the derived transform matrix nad project that warped image on a plain surface</p>
                  <img class="img-fluid d-block mx-auto" src="img/portfolio/image_mosaic/img1.jpg" alt="">
                  <img class="img-fluid d-block mx-auto" src="img/portfolio/image_mosaic/img2.jpg" alt="">
                  <h5>Image Blending</h5>
                  <p>Using Center-Weighting algorithm (compute the the distance from each pixel to 4 boundaries of the image and take the the smallest ratio                   
                    between two distances and the dimension of image as the corresponding pixel
                    value on mask matrix). The mask we derived is shown in the following image:</p>
                  <img class="img-fluid d-block mx-auto" src="img/portfolio/image_mosaic/mask.jpg" alt="">
                  <p>For each image, I derive a mask and then warp the mask just as warp the image</p>
                  <img class="img-fluid d-block mx-auto" src="img/portfolio/image_mosaic/before.jpg" alt="">
                  <img class="img-fluid d-block mx-auto" src="img/portfolio/image_mosaic/after.jpg" alt="">
                  <h5>Cropping</h5>
                  <p>After doing image stitching and image blending, I get the panorama look as following</p>
                  <img class="img-fluid d-block mx-auto" src="img/portfolio/image_mosaic/1.jpg" alt="">
                  <img class="img-fluid d-block mx-auto" src="img/portfolio/image_mosaic/2.jpg" alt="">
                  <img class="img-fluid d-block mx-auto" src="img/portfolio/image_mosaic/3.jpg" alt="">
                  <p>Use pythong to find the largest rectangle that don’t include the black region in the
                    panorama image, I get the final panorama look as following</p>
                    <img class="img-fluid d-block mx-auto" src="img/portfolio/image_mosaic/1_a.jpg" alt="">
                    <img class="img-fluid d-block mx-auto" src="img/portfolio/image_mosaic/2_a.jpg" alt="">
                    <img class="img-fluid d-block mx-auto" src="img/portfolio/image_mosaic/3_a.jpg" alt="">
                  <ul class="list-inline">
                  <p><a class="boxed" href="https://drive.google.com/file/d/1p8h66kcTu3J3DAQ-OETgzaHgj101Kw8o/view?usp=sharing"><font color="red"><b>Report</font></a></p>
                  </ul>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fas fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Dynamics -->
    <div class="portfolio-modal modal fade" id="dynamics" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-8 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h3 class="text-uppercase">Pin-triangle Dynamics Simulation </h3>
                  <a class="boxed">Python</a>&ensp;<a class="boxed">Dynamics</a>&ensp;<a class="boxed">Simulation</a>
                  <p></p>
                  <h4>Brief Description</h4>
                  <p>This project is a dynamics simulation of a triangle bouncing in the enclosed rectangle. This project shows techniques expansion from theory and ability of building physical model.  </p>
                  <p></p>
                  <h5>dynamic model</h5>
                  <p>The pictured pin-triangle is a constrained system involving 2 bodies: a equilateral triangle and a square. the triangle has length d = 3, mass m =0.5 and rotational inertia J=1 (assuming that the center of mass is at the center of geometry). The square has length D = 20, mass M = 5 and rotational inertia J=3 (assuming that the center of mass is at the center of geometry). The triangle has configuration (x,y,\theta_t) and the square has an angle \theta_s relative to the world frame. The triangle is constrainted to not bounce out of the square.</p>
                  <img class="img-fluid d-block mx-auto" src="img/portfolio/dynamics_proj/model.png" alt="">
                  <ul class="list-inline">
                 	<p><a class="boxed" href="https://colab.research.google.com/drive/1d3GrjH75j-MqSYNUyhwd3FWeb2eVgY4D"><font color="red"><b>Python Source Code</font></a></p>
                    
                   
                  </ul>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fas fa-times"></i>
                    Close Project</button>
                    
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

   

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Contact form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/agency.min.js"></script>

  </body>

</html>
